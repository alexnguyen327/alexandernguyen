# %% [markdown]
# # **MOVIE SUCCESS IN RELATION TO ITS FILM DISTRIBUTION COMPANY**
# 
# Author: [Alexander Nguyen]
# 
# Course Project, UC Irvine, Math 10, S24
# 
# I would like to post my notebook on the course's website. [Yes]

# %% [markdown]
# # INTRODUCTION
# 
# The movie industry is an extremely competitive environment, where production companies constantly aim to release movies that do well in the box-office while also pleasing audiences. These companies will pour hundreds of millions of dollars into these movies in hopes of achieving success. In the dataset I have chosen, I have a list of 7668 movies from 1986 to 2016. By analyzing the data, I hope to find if there are any correlations between the commercial and popularity success of a movie alongside it's company. I also hope to look for any other correlations and create predictions based on these correlations.

# %% [markdown]
# # EXPLORING THE DATA
# 
# First, we load up the csv file through pandas and display the first 5 rows of the datatable

# %%
import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt

# %%
df = pd.read_csv('movies.csv.zip')
df.head()

# %% [markdown]
# We want to drop unnecessary columns, which include the release date, director, writer, star, country, rating, runtime, and genre of the movie, as we mainly want to focus on how well the movie performed based on it's budget, production company, etc.

# %%
df = df.drop(['released', 'director', 'writer', 'star', 'country', 'rating', 'runtime', 'genre'], axis=1)
df.head(5)


# %%
print(f'Percentage of Missing Values in Budget Column: {(len(df[df['budget'].isnull()]) / 7668) * 100 :.2f}%')
print(f'Percentage of Missing Values in Gross Column: {(len(df[df['gross'].isnull()]) / 7668) * 100 :.2f}%')
print(f'Percentage of Missing Values in Score Column: {(len(df[df['score'].isnull()]) / 7668) * 100 :.2f}%')
print(f'Percentage of Missing Values in Votes Column: {(len(df[df['votes'].isnull()]) / 7668) * 100 :.2f}%')

# %% [markdown]
# There are missing data values for most columns, but the columns that we will focus on that have missing values contain the score, votes, budget, and gross. Since the vote, score, and gross columns only have a small percentage of rows with missing values, we can easily drop them.

# %%
df_new = df
df_new.dropna(subset = ['score','votes','gross'], inplace=True)


# %% [markdown]
# Since 28.31% of the budget is missing, we need to use data imputation to replace the missing values. To figure out what measure of data we replace the missing data with, we have to display the budget data.

# %%
sns.boxplot(data=df_new, x="budget")

# %% [markdown]
# We can see that there is a large number of outliers in the distribution of the budget for movies, so the best measure of spread would be the median. We can then impute the median of the budget into the missing values to fill them in.

# %%
# from sklearn.impute import SimpleImputer
budget_median = df_new['budget'].median()
print(f'Median : ${budget_median}')
# imputer = SimpleImputer(missing_values = np.nan, strategy = 'median')
# df['budget'] = imputer.fit(df['budget'])
df_new['budget'] = df_new['budget'].fillna(budget_median)

# %% [markdown]
# We want to analyze the major movie companies of this dataset, as we want to analyze major movies and compare the most well-known companies. I have decided to reduce the list to the top 5 companies, so that I can better analyze any correlation between the companies and features.

# %%
df_new['company'].value_counts().head(5)

# %%
company = df_new['company'].value_counts()
top_5 = company.nlargest(5).index.tolist()
subset_company = df_new[df_new['company'].isin(top_5)]

# %%
subset_company['net gain/loss'] = subset_company.apply(lambda row: row['gross'] - row['budget'], axis=1)
subset_company = subset_company.reset_index(drop=True)
subset_company

# %% [markdown]
# # ANALYZING DATA
# 
# We can begin by analyzing the data through displaying basic information about the data, searching for any patterns they may display.

# %%
subset_company.dtypes

# %%
subset_company.shape

# %% [markdown]
# Let's first take a look at the score category. We can analyze the distribution of score and how it relates to the most popular film production companies.

# %%
subset_company['score'].describe()

# %%
sns.displot(subset_company, x="score")

# %% [markdown]
# We see that there is a relatively normal distribution that's slightly skewed left between the scores of movies, averaging from a score of 6-7. 

# %%
sns.displot(subset_company, x="score", hue=subset_company['company'])

# %% [markdown]
# We can now see the score distribution between the top 5 companies. Notably, Warner Bros. tends to have higher scores, Universal Pictures tends to be have average to higher scores, and Columbia Pictures tends to have average to lower scores.

# %%
ax = sns.scatterplot(data=subset_company, x='budget',y='gross')

# %% [markdown]
# Comparing the budget with the gross of movies from the top 5 production companies, we see that there are major outliers in gross that affect the visualization of the scatterplot. We can set a limit for the gross to get rid of some outliers, and get a better representation of the data

# %%
ax = sns.scatterplot(data=subset_company, x='budget',y='gross')
ax.set(ylim=(0,1000000000))

# %% [markdown]
# We can now see a better visualization of the budget vs gross, in which we see a slight positive correlation. We will further explore this correlation later on.

# %%
ax = sns.boxplot(subset_company, x='gross', y=subset_company['company'])
ax.set(xlabel='gross (in billions)')

# %%
ax = sns.boxplot(subset_company, x='budget', y=subset_company['company'])
ax.set(xlabel='budget (by 100 million)')


# %% [markdown]
# Looking at the boxplots for the top 5 companies alongside their budget and grossing, we can once again see that there are extreme outliers for both. This makes sense, as each movie production company has very few successful movies that reach such high grossing, and certain movies receive major budgets depending on the promise of the movie or projected grossing. However, we see that Warner Bros. has spent the most on movies in terms of budget, yet Twentieth Century Fox seems to have had the most commercially successful movies, revealing that even if the movie company spends a lot on budget, they may not receive the most success in the box-office.

# %%
corr = subset_company[["gross", "budget", "score", "votes", 'net gain/loss']].corr()
sns.heatmap(corr, annot=True)


# %% [markdown]
# Using a heatmap, we now see the correlation between the different features we have in our dataset. Budget and gross have the strongest correlation, which helps prove our prediction that the more money you put into a movie, the better commercial success you receive. We also have a strong correlation between gross and votes, which also makes sense. As more people view a movie, the revenue of a movie increases.

# %% [markdown]
# # MACHINE LEARNING
# 
# After looking through the data and searching for patterns, we can attempt to make predictions based on the data. We can start with making predictions on the specific movie company based on the features "gross", "budget", "score", and "votes", to see if there are any differing featuristics between the top 5 movie companies we have chosen.

# %%
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression

# %%
features = ['budget','gross','score','votes']
subset_company['company'] = subset_company['company'].replace({'Universal Pictures': 0, 'Warner Bros.': 1, 'Columbia Pictures': 2, 'Paramount Pictures' : 3, 'Twentieth Century Fox' : 4})

for feature in features:
    lm = LinearRegression()
    lm.fit(subset_company[[feature]], subset_company['company'])
    score = lm.score(subset_company[[feature]], subset_company['company'])
    print(f'{feature} R^2 Value: {score}')

# %% [markdown]
# I started with single variable linear regression, and fit each feature into a linear regression model to see which was the best predictor of the company, using the $R^2$ value to determine how well the model was. Unfortunately, none of the features can predict the company as shown by the scores. This shows us that none of the top 5 companies stand out in terms of commercial or populairty success, which we were starting to see through the analyzation of the data earlier. Although there are no correlations between any of the features and the company, we did learn that there was a strong correlation between budget and gross, which can try further exploring through a linear regression.

# %%
lm = LinearRegression()
lm.fit(subset_company[['budget']], subset_company['gross'])
score = lm.score(subset_company[['budget']], subset_company['gross'])
print(f'R2 = {score}')


# %% [markdown]
# After fitting the model, we get an $R^2$ value of .46, which is pretty weak, revealing that there isn't a strong linear relationship between the budget and gross of a movie.

# %% [markdown]
# We can also take a look at the relationship between votes and net gain/loss, which we saw a slightly strong correlation in earlier. Logically, a movie's votes and score will have an affect on the net gain/loss, as the more popular a movie is, the more people there will be to watch it, increasing box office. We can first try fitting it onto a linear regression, but this time validating the $R^2$ value using 5-fold validation.

# %%
from sklearn.model_selection import cross_val_score, KFold
from sklearn.preprocessing import MinMaxScaler

features = ['votes']

X = subset_company[features]
y = subset_company['net gain/loss']
# Setup 5-fold cross-validation
kf = KFold(n_splits=5, shuffle=True, random_state=1)

# Perform cross-validation
r2_scores = cross_val_score(lm, X, y, cv=kf, scoring='r2')

# Calculate average and standard deviation of R-squared scores
average_r2 = np.mean(r2_scores)
std_r2 = np.std(r2_scores)

print(f'Average R-squared: {average_r2:.5f}')
print(f'Standard Deviation of R-squared: {std_r2:.5f}')


# %% [markdown]
# Again, we find a weak average $R^2$ value between votes and net gain/loss. However, we can instead try and fit the data onto a logistic regression model using classification. First, I wanted to see all the titles that had a negative revenue. 

# %%
titles = []
for i in range(len(subset_company['net gain/loss'])):
    if subset_company.loc[i,'net gain/loss'] < 0:
        titles.append(subset_company.loc[i,'name'])

print(len(titles))

# %% [markdown]
# We want to have two classes, whether a movie has a net gain or net loss in the box-office. I created a for-loop to create class 0, for when a movie has a net loss, and a class 1, if a movie has a positive net gain.

# %%
for i in range(len(subset_company['net gain/loss'])):
    if subset_company.loc[i,'net gain/loss'] < 0:
        subset_company.loc[i,'net gain/loss'] = 0
    elif subset_company.loc[i,'net gain/loss'] > 0:
        subset_company.loc[i,'net gain/loss'] = 1

subset_company

# %% [markdown]
# I then scaled the features using a standard scaler, with a mean of 0 and standard deviation of 1. I then fit the data onto a logistic regression model. 

# %%
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
features = ['votes']
subset_company[features] = scaler.fit_transform(subset_company[features])

# %%
from sklearn.linear_model import LogisticRegression

X = subset_company[features]
y = subset_company['net gain/loss']
clf = LogisticRegression(multi_class='multinomial', penalty=None)
clf.fit(X, y)
print(f'R^2 value: {clf.score(X, y)}')

# %% [markdown]
# After fitting the model, we get a stronger $R^2$ value of 0.812, which reveals that with our model, we have a strong probability of predicting whether a movie will have a positive or negative revenue in the box-office based on how popular the movie is among viewers.

# %% [markdown]
# # EXTRA

# %% [markdown]
# For this portion, we will be using a different machine learning tool to create a model fitting votes to predict the net gain/loss. I downloaded the package TensorFlow, as it allows for efficient deep learning that's quick and reproducible.

# %%
from sklearn.model_selection import train_test_split

# %% [markdown]
# First, we're going to split our data into training and testing data, in order to have a data set dedicated towards training our model, and a set of data to test it on for accuracy.

# %%
X = X = subset_company[features]
y = subset_company['net gain/loss']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)



# %%
import tensorflow as tf
import keras as keras
from sklearn.metrics import accuracy_score

# %% [markdown]
# From Tensorflow, we want to create a model using tf.keras.Sequential(), which will be our main model class that we fit our data onto. The Dense feature is a layer that allows us to build hidden layers within our model, which in this case is 2 hidden layers. The first hidden layer takes our raw data and passes it through a relu activation function, which takes our data and converts the output to a minimum of zero and an unlimited upward value. Our second hidden layer determines a true or false output, which in this case is whether a movie has a positive or negative net gain. We use the Sigmoid function to convert the value to 0 or 1, with 0 being that the movie had a negative gain and 1 being that the movie had a positive gain.

# %%
model = tf.keras.Sequential()
Dense = tf.keras.layers.Dense
model.add(Dense(units=32, activation='relu', input_dim=len(X_train.columns)))
model.add(Dense(units=64, activation='relu'))
model.add(Dense(units=1, activation='sigmoid'))


# %% [markdown]
# We want to determine how well our fit is, so we want to know the binary cross entropy loss as well as the $R^2$ value.

# %%
model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])

# %%
model.fit(X_train, y_train, epochs=500, batch_size=32)

# %%
y_hat = model.predict(X_test)
y_hat = [0 if x <0.5 else 1 for x in y_hat]


accuracy_score(y_test,y_hat)

# %% [markdown]
# After training our model for different periods of time, I've found that the $R^2$ value of the model is around the same compared to our logistic regression model. However, this model is much nicer to use as it allows us to determine how long we want to train our model for, while also allowing us to save the model and reproduce it for later use.

# %% [markdown]
# # SUMMARY
# 
# After exploring the dataset of movie info and using analysis methods such as linear regression and classification, I was able to come up with results both expected and unexpected. 
# 
# My initial attempt to find a correlation between votes, score, gross, and budget in relation to a company was unsuccessful. Using a linear regression to fit the features produced extremely low accuracy . With this, I found out that between the 5 most frequent companies in my dataset, the relation between the individual features and individual companies were not significant, such that no company performed noticably better or worse within one of the features. We can conclude that the companies in question are all similar competitors against each other, with no company being extremely differentiable from the rest.
# 
# I then explored another correlation between the budget and gross of a movie, fitting the budget onto a linear regression model to predict the gross. Once again, it produced a weak accuracy score, revealing that the amount of budget does not always determine how much a movie will make.
# 
# However, when exploring the relation between votes and the net gain/loss of revenue for a movie, I found a good correlation. Although a linear regression model including validation with KNN produced a low average $R^2$ value, fitting the data onto a logistic regression gave a strong accuracy score, using binary classification. My two classes consisted of either a positive or negative net revenue for the movie, and we were able to get around 0.8 for the $R^2$ value, which is strong. We were also able to get a similar score using Tensorflow. This correlation makes sense, as the more people watch a movie, the more revenue a movie will gross.
# 
# # REFERENCES
# 
# Source of Dataset: https://www.kaggle.com/datasets/danielgrijalvas/movies?resource=download
# 
# Tutorial for Tensorflow: https://www.youtube.com/watch?v=6_2hzRopPbQ&ab_channel=NicholasRenotte
# 
# 


